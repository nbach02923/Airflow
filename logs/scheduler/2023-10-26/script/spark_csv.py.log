[2023-10-26T03:52:36.048+0000] {processor.py:156} INFO - Started process (PID=41) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:52:36.327+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:52:36.417+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:52:36.412+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:53:07.819+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:07.699+0000] {timeout.py:68} ERROR - Process timed out, PID: 41
[2023-10-26T03:53:08.297+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:07.869+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 41
[2023-10-26T03:53:08.336+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:08.336+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T03:53:08.406+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:08.358+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 41

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T03:53:08.419+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:08.419+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T03:53:08.512+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:08.438+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T03:53:08.543+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:53:08.892+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 33.093 seconds
[2023-10-26T03:53:39.268+0000] {processor.py:156} INFO - Started process (PID=168) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:53:39.269+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:53:39.270+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:53:39.270+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:53:52.366+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:53:52.386+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 13.120 seconds
[2023-10-26T03:54:23.211+0000] {processor.py:156} INFO - Started process (PID=313) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:54:23.213+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:54:23.214+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:54:23.214+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:54:35.490+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:54:35.525+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 12.312 seconds
[2023-10-26T03:55:05.788+0000] {processor.py:156} INFO - Started process (PID=447) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:05.790+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:55:05.791+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:55:05.791+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:16.209+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:16.235+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.450 seconds
[2023-10-26T03:55:46.766+0000] {processor.py:156} INFO - Started process (PID=591) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:46.768+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:55:46.770+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:55:46.770+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:52.399+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:55:52.415+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.654 seconds
[2023-10-26T03:56:23.246+0000] {processor.py:156} INFO - Started process (PID=728) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:56:23.248+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:56:23.249+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:56:23.249+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:56:31.051+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:56:31.038+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 26, in <module>
    os.path.join(folder, file) for file in os.listdir(folder) if file.endswith(".csv")
OSError: [Errno 12] Cannot allocate memory: '/opt/airflow/dags/data/real_estate'
[2023-10-26T03:56:31.057+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:56:31.159+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.915 seconds
[2023-10-26T03:57:01.516+0000] {processor.py:156} INFO - Started process (PID=863) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:01.518+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:57:01.519+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:57:01.519+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:07.197+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:07.206+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.694 seconds
[2023-10-26T03:57:37.314+0000] {processor.py:156} INFO - Started process (PID=999) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:37.316+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:57:37.318+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:57:37.317+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:46.201+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:57:46.215+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.904 seconds
[2023-10-26T03:58:16.272+0000] {processor.py:156} INFO - Started process (PID=1144) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:58:16.273+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:58:16.275+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:58:16.275+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:58:24.146+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:58:24.160+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.891 seconds
[2023-10-26T03:59:55.839+0000] {processor.py:156} INFO - Started process (PID=30) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T03:59:55.840+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T03:59:55.842+0000] {logging_mixin.py:117} INFO - [2023-10-26T03:59:55.842+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:00:22.697+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:00:22.751+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 26.919 seconds
[2023-10-26T04:00:53.238+0000] {processor.py:156} INFO - Started process (PID=178) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:00:53.239+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:00:53.240+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:00:53.240+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:01:04.152+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:01:04.163+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.928 seconds
[2023-10-26T04:01:34.253+0000] {processor.py:156} INFO - Started process (PID=315) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:01:34.254+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:01:34.256+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:01:34.256+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:01:47.153+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:01:47.172+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 12.925 seconds
[2023-10-26T04:02:17.376+0000] {processor.py:156} INFO - Started process (PID=457) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:02:17.378+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:02:17.379+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:02:17.379+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:02:24.118+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:02:24.132+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.760 seconds
[2023-10-26T04:02:54.856+0000] {processor.py:156} INFO - Started process (PID=591) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:02:54.857+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:02:54.862+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:02:54.861+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:03:02.112+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:03:02.120+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.267 seconds
[2023-10-26T04:03:32.641+0000] {processor.py:156} INFO - Started process (PID=724) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:03:32.642+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:03:32.643+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:03:32.643+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:03:38.955+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:03:38.990+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.352 seconds
[2023-10-26T04:04:09.570+0000] {processor.py:156} INFO - Started process (PID=861) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:09.571+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:04:09.572+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:04:09.572+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:16.555+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:16.562+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.994 seconds
[2023-10-26T04:04:46.666+0000] {processor.py:156} INFO - Started process (PID=995) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:46.668+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:04:46.669+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:04:46.668+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:53.261+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:04:53.267+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.605 seconds
[2023-10-26T04:05:23.342+0000] {processor.py:156} INFO - Started process (PID=1129) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:05:23.344+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:05:23.346+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:05:23.346+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:05:30.560+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:05:30.568+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.220 seconds
[2023-10-26T04:06:00.762+0000] {processor.py:156} INFO - Started process (PID=1272) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:00.765+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:06:00.767+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:06:00.766+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:05.866+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:05.875+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.117 seconds
[2023-10-26T04:06:36.678+0000] {processor.py:156} INFO - Started process (PID=1405) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:36.681+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:06:36.682+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:06:36.682+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:41.667+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:06:41.673+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.998 seconds
[2023-10-26T04:07:11.763+0000] {processor.py:156} INFO - Started process (PID=1542) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:11.764+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:07:11.765+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:07:11.765+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:16.892+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:16.899+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.138 seconds
[2023-10-26T04:07:47.439+0000] {processor.py:156} INFO - Started process (PID=1676) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:47.441+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:07:47.442+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:07:47.442+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:52.080+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:07:52.089+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.653 seconds
[2023-10-26T04:08:22.313+0000] {processor.py:156} INFO - Started process (PID=1810) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:08:22.314+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:08:22.316+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:08:22.315+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:08:27.013+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:08:27.021+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.711 seconds
[2023-10-26T04:08:57.151+0000] {processor.py:156} INFO - Started process (PID=1944) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:08:57.152+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:08:57.154+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:08:57.153+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:09:02.449+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:09:02.467+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.320 seconds
[2023-10-26T04:09:32.916+0000] {processor.py:156} INFO - Started process (PID=2077) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:09:32.918+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:09:32.919+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:09:32.919+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:09:41.092+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:09:41.110+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.196 seconds
[2023-10-26T04:10:11.912+0000] {processor.py:156} INFO - Started process (PID=2212) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:11.914+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:10:11.915+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:10:11.915+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:19.405+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:19.411+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.502 seconds
[2023-10-26T04:10:49.829+0000] {processor.py:156} INFO - Started process (PID=2356) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:49.831+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:10:49.833+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:10:49.833+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:56.802+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:10:56.819+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.994 seconds
[2023-10-26T04:11:27.019+0000] {processor.py:156} INFO - Started process (PID=2491) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:11:27.021+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:11:27.022+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:11:27.022+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:11:32.130+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:11:32.139+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.124 seconds
[2023-10-26T04:12:02.193+0000] {processor.py:156} INFO - Started process (PID=2625) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:02.195+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:12:02.196+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:12:02.196+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:08.407+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:08.421+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.230 seconds
[2023-10-26T04:12:38.473+0000] {processor.py:156} INFO - Started process (PID=2759) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:38.474+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:12:38.475+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:12:38.475+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:43.298+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:12:43.312+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.841 seconds
[2023-10-26T04:13:14.059+0000] {processor.py:156} INFO - Started process (PID=2892) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:14.061+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:13:14.062+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:13:14.062+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:20.615+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:20.633+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.577 seconds
[2023-10-26T04:13:50.754+0000] {processor.py:156} INFO - Started process (PID=3027) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:50.755+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:13:50.756+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:13:50.756+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:59.982+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:13:59.992+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 9.234 seconds
[2023-10-26T04:14:30.584+0000] {processor.py:156} INFO - Started process (PID=3165) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:14:30.586+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:14:30.587+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:14:30.586+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:14:38.517+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:14:38.526+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.944 seconds
[2023-10-26T04:15:08.765+0000] {processor.py:156} INFO - Started process (PID=3309) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:08.767+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:15:08.768+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:15:08.768+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:15.198+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:15.207+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.444 seconds
[2023-10-26T04:15:45.435+0000] {processor.py:156} INFO - Started process (PID=3444) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:45.437+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:15:45.438+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:15:45.438+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:50.881+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:15:50.887+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.456 seconds
[2023-10-26T04:16:21.134+0000] {processor.py:156} INFO - Started process (PID=3579) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:16:21.135+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:16:21.136+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:16:21.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:16:27.657+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:16:27.664+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.533 seconds
[2023-10-26T04:16:58.296+0000] {processor.py:156} INFO - Started process (PID=3714) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:16:58.298+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:16:58.299+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:16:58.299+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:17:05.763+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:17:05.774+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.478 seconds
[2023-10-26T04:17:36.248+0000] {processor.py:156} INFO - Started process (PID=3848) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:17:36.249+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:17:36.250+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:17:36.250+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:17:43.190+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:17:43.199+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.953 seconds
[2023-10-26T04:18:13.523+0000] {processor.py:156} INFO - Started process (PID=3991) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:18:13.524+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:18:13.526+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:18:13.526+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:18:21.802+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:18:21.819+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.299 seconds
[2023-10-26T04:18:52.137+0000] {processor.py:156} INFO - Started process (PID=4125) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:18:52.138+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:18:52.139+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:18:52.139+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:19:02.804+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:19:02.814+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.666 seconds
[2023-10-26T04:19:33.452+0000] {processor.py:156} INFO - Started process (PID=4261) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:19:33.454+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:19:33.455+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:19:33.455+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:19:42.077+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:19:42.084+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.635 seconds
[2023-10-26T04:20:12.673+0000] {processor.py:156} INFO - Started process (PID=4405) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:12.675+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:20:12.676+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:20:12.675+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:19.294+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:19.306+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.636 seconds
[2023-10-26T04:20:49.603+0000] {processor.py:156} INFO - Started process (PID=4539) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:49.605+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:20:49.607+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:20:49.606+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:57.969+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:20:57.976+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.375 seconds
[2023-10-26T04:21:28.725+0000] {processor.py:156} INFO - Started process (PID=4672) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:21:28.729+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:21:28.731+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:21:28.730+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:21:37.961+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:21:37.971+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 9.246 seconds
[2023-10-26T04:22:08.420+0000] {processor.py:156} INFO - Started process (PID=4807) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:22:08.422+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:22:08.424+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:22:08.424+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:22:20.914+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:22:20.925+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 12.508 seconds
[2023-10-26T04:22:51.124+0000] {processor.py:156} INFO - Started process (PID=4942) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:22:51.125+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:22:51.127+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:22:51.127+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:23:01.725+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:23:01.736+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.610 seconds
[2023-10-26T04:23:32.031+0000] {processor.py:156} INFO - Started process (PID=5084) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:23:32.066+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:23:32.085+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:23:32.085+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:24:02.762+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.739+0000] {timeout.py:68} ERROR - Process timed out, PID: 5084
[2023-10-26T04:24:02.802+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.773+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 5084
[2023-10-26T04:24:02.807+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.807+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T04:24:02.835+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.828+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 5084

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T04:24:02.836+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T04:24:02.885+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:02.849+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T04:24:02.903+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:24:04.478+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 32.419 seconds
[2023-10-26T04:24:34.857+0000] {processor.py:156} INFO - Started process (PID=5218) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:24:34.860+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:24:34.862+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:24:34.862+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:24:47.957+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:24:47.980+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 13.125 seconds
[2023-10-26T04:25:18.821+0000] {processor.py:156} INFO - Started process (PID=5363) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:25:18.823+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:25:18.824+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:25:18.824+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:25:27.134+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:25:27.150+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.331 seconds
[2023-10-26T04:25:57.614+0000] {processor.py:156} INFO - Started process (PID=5497) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:25:57.615+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:25:57.616+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:25:57.616+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:26:05.575+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:26:05.588+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.971 seconds
[2023-10-26T04:26:35.723+0000] {processor.py:156} INFO - Started process (PID=5631) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:26:35.727+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:26:35.729+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:26:35.729+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:26:51.301+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:26:51.324+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 15.613 seconds
[2023-10-26T04:27:21.673+0000] {processor.py:156} INFO - Started process (PID=5777) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:27:21.675+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:27:21.677+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:27:21.677+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:27:30.552+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:27:30.561+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.891 seconds
[2023-10-26T04:28:00.922+0000] {processor.py:156} INFO - Started process (PID=5912) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:00.924+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:28:00.925+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:28:00.925+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:08.683+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:08.691+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.767 seconds
[2023-10-26T04:28:39.522+0000] {processor.py:156} INFO - Started process (PID=6057) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:39.524+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:28:39.525+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:28:39.525+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:47.797+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:28:47.806+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.287 seconds
[2023-10-26T04:29:18.436+0000] {processor.py:156} INFO - Started process (PID=6192) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:29:18.437+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:29:18.438+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:29:18.438+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:29:28.917+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:29:28.926+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.493 seconds
[2023-10-26T04:29:59.114+0000] {processor.py:156} INFO - Started process (PID=6329) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:29:59.116+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:29:59.117+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:29:59.117+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:30:08.379+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:30:08.387+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 9.273 seconds
[2023-10-26T04:30:39.014+0000] {processor.py:156} INFO - Started process (PID=6472) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:30:39.016+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:30:39.017+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:30:39.017+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:30:46.537+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:30:46.544+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.532 seconds
[2023-10-26T04:31:16.884+0000] {processor.py:156} INFO - Started process (PID=6606) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:31:16.886+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:31:16.887+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:31:16.887+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:31:23.655+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:31:23.666+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.785 seconds
[2023-10-26T04:31:53.759+0000] {processor.py:156} INFO - Started process (PID=6740) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:31:53.761+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:31:53.762+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:31:53.762+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:32:04.346+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:32:04.355+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.586 seconds
[2023-10-26T04:32:34.861+0000] {processor.py:156} INFO - Started process (PID=6886) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:32:34.862+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:32:34.863+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:32:34.863+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:32:44.699+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:32:44.706+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 9.848 seconds
[2023-10-26T04:33:14.766+0000] {processor.py:156} INFO - Started process (PID=7020) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:33:14.768+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:33:14.770+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:33:14.769+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:33:22.774+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:33:22.807+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.041 seconds
[2023-10-26T04:33:52.978+0000] {processor.py:156} INFO - Started process (PID=7153) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:33:52.979+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:33:52.980+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:33:52.980+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:34:03.539+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:34:03.547+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.554 seconds
[2023-10-26T04:34:34.157+0000] {processor.py:156} INFO - Started process (PID=7287) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:34:34.158+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:34:34.160+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:34:34.160+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:34:42.114+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:34:42.124+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.970 seconds
[2023-10-26T04:35:12.539+0000] {processor.py:156} INFO - Started process (PID=7431) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:35:12.540+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:35:12.541+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:35:12.541+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:35:22.998+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:35:23.008+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.472 seconds
[2023-10-26T04:35:53.467+0000] {processor.py:156} INFO - Started process (PID=7568) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:35:53.470+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:35:53.471+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:35:53.471+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:36:02.368+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:36:02.382+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.903 seconds
[2023-10-26T04:36:33.160+0000] {processor.py:156} INFO - Started process (PID=7702) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:36:33.162+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:36:33.164+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:36:33.164+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:36:41.700+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:36:41.708+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.552 seconds
[2023-10-26T04:37:12.129+0000] {processor.py:156} INFO - Started process (PID=7837) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:12.131+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:37:12.132+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:37:12.132+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:20.192+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:20.200+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.074 seconds
[2023-10-26T04:37:50.628+0000] {processor.py:156} INFO - Started process (PID=7981) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:50.630+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:37:50.631+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:37:50.631+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:57.202+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:37:57.212+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.587 seconds
[2023-10-26T04:38:27.403+0000] {processor.py:156} INFO - Started process (PID=8116) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:38:27.407+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:38:27.409+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:38:27.409+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:38:38.758+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:38:38.769+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 11.361 seconds
[2023-10-26T04:39:08.988+0000] {processor.py:156} INFO - Started process (PID=8251) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:08.989+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:39:08.991+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:39:08.990+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:16.523+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:16.531+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.546 seconds
[2023-10-26T04:39:46.966+0000] {processor.py:156} INFO - Started process (PID=8395) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:46.969+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:39:46.973+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:39:46.972+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:57.450+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:39:57.459+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.498 seconds
[2023-10-26T04:40:28.134+0000] {processor.py:156} INFO - Started process (PID=8529) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:40:28.135+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:40:28.137+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:40:28.137+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:40:36.384+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:40:36.392+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.257 seconds
[2023-10-26T04:41:07.073+0000] {processor.py:156} INFO - Started process (PID=8663) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:07.075+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:41:07.077+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:41:07.076+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:17.462+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:17.471+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.402 seconds
[2023-10-26T04:41:47.656+0000] {processor.py:156} INFO - Started process (PID=8808) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:47.657+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:41:47.659+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:41:47.658+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:54.708+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:41:54.718+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.066 seconds
[2023-10-26T04:42:25.504+0000] {processor.py:156} INFO - Started process (PID=8944) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:42:25.506+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:42:25.508+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:42:25.508+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:42:32.827+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:42:32.838+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.323 seconds
[2023-10-26T04:43:02.971+0000] {processor.py:156} INFO - Started process (PID=9079) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:02.972+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:43:02.973+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:43:02.973+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:10.089+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:10.096+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.128 seconds
[2023-10-26T04:43:40.792+0000] {processor.py:156} INFO - Started process (PID=9222) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:40.794+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:43:40.796+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:43:40.795+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:54.965+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:43:54.978+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 14.189 seconds
[2023-10-26T04:44:25.430+0000] {processor.py:156} INFO - Started process (PID=9359) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:44:25.434+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:44:25.437+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:44:25.436+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:44:32.961+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:44:32.971+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.537 seconds
[2023-10-26T04:45:03.030+0000] {processor.py:156} INFO - Started process (PID=9494) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:03.031+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:45:03.032+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:45:03.032+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:11.467+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:11.475+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.450 seconds
[2023-10-26T04:45:41.627+0000] {processor.py:156} INFO - Started process (PID=9636) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:41.628+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:45:41.629+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:45:41.629+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:48.389+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:45:48.405+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.781 seconds
[2023-10-26T04:46:18.568+0000] {processor.py:156} INFO - Started process (PID=9769) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:46:18.569+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:46:18.572+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:46:18.571+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:46:26.562+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:46:26.580+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.016 seconds
[2023-10-26T04:46:57.140+0000] {processor.py:156} INFO - Started process (PID=9905) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:46:57.141+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:46:57.143+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:46:57.143+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:47:04.077+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:47:04.088+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.944 seconds
[2023-10-26T04:47:34.712+0000] {processor.py:156} INFO - Started process (PID=10040) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:47:34.713+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:47:34.714+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:47:34.714+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:47:42.481+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:47:42.489+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.780 seconds
[2023-10-26T04:48:12.678+0000] {processor.py:156} INFO - Started process (PID=10186) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:12.679+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:48:12.681+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:48:12.680+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:19.682+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:19.690+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.015 seconds
[2023-10-26T04:48:50.044+0000] {processor.py:156} INFO - Started process (PID=10320) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:50.045+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:48:50.047+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:48:50.047+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:56.982+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:48:56.992+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.951 seconds
[2023-10-26T04:49:27.058+0000] {processor.py:156} INFO - Started process (PID=10455) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:49:27.060+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:49:27.061+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:49:27.061+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:49:33.998+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:49:34.010+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.947 seconds
[2023-10-26T04:50:04.331+0000] {processor.py:156} INFO - Started process (PID=10599) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:04.333+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:50:04.334+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:50:04.333+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:11.772+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:11.779+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.450 seconds
[2023-10-26T04:50:41.882+0000] {processor.py:156} INFO - Started process (PID=10733) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:41.884+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:50:41.885+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:50:41.885+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:49.039+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:50:49.045+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.167 seconds
[2023-10-26T04:51:19.425+0000] {processor.py:156} INFO - Started process (PID=10868) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:51:19.426+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:51:19.428+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:51:19.427+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:51:27.313+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:51:27.321+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.899 seconds
[2023-10-26T04:51:57.598+0000] {processor.py:156} INFO - Started process (PID=11006) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:51:57.599+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:51:57.600+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:51:57.600+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:52:06.257+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:52:06.273+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.675 seconds
[2023-10-26T04:52:36.450+0000] {processor.py:156} INFO - Started process (PID=11150) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:52:36.451+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:52:36.453+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:52:36.453+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:52:44.245+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:52:44.253+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.807 seconds
[2023-10-26T04:53:15.007+0000] {processor.py:156} INFO - Started process (PID=11284) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:53:15.009+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:53:15.010+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:53:15.010+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:53:22.738+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:53:22.753+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.749 seconds
[2023-10-26T04:53:53.105+0000] {processor.py:156} INFO - Started process (PID=11418) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:53:53.106+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:53:53.107+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:53:53.107+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:54:00.949+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:54:00.958+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.856 seconds
[2023-10-26T04:54:31.449+0000] {processor.py:156} INFO - Started process (PID=11554) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:54:31.450+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:54:31.452+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:54:31.452+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:54:38.618+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:54:38.625+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.175 seconds
[2023-10-26T04:55:09.310+0000] {processor.py:156} INFO - Started process (PID=11699) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:09.311+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:55:09.312+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:55:09.312+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:15.636+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:15.644+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.337 seconds
[2023-10-26T04:55:45.879+0000] {processor.py:156} INFO - Started process (PID=11833) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:45.880+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:55:45.882+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:55:45.881+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:54.000+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:55:54.007+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.131 seconds
[2023-10-26T04:56:24.272+0000] {processor.py:156} INFO - Started process (PID=11967) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:56:24.273+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:56:24.274+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:56:24.274+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:56:31.801+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:56:31.812+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.543 seconds
[2023-10-26T04:57:02.397+0000] {processor.py:156} INFO - Started process (PID=12111) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:02.399+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:57:02.401+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:57:02.400+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:09.656+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:09.665+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.272 seconds
[2023-10-26T04:57:40.000+0000] {processor.py:156} INFO - Started process (PID=12247) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:40.001+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:57:40.002+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:57:40.002+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:47.162+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:57:47.151+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 26, in <module>
    os.path.join(folder, file) for file in os.listdir(folder) if file.endswith(".csv")
OSError: [Errno 12] Cannot allocate memory: '/opt/airflow/dags/data/real_estate'
[2023-10-26T04:57:47.175+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:57:47.288+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.291 seconds
[2023-10-26T04:58:17.842+0000] {processor.py:156} INFO - Started process (PID=12382) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:58:17.843+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:58:17.844+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:58:17.844+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:58:26.530+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:58:26.546+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.707 seconds
[2023-10-26T04:58:56.751+0000] {processor.py:156} INFO - Started process (PID=12516) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:58:56.752+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:58:56.754+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:58:56.753+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:59:04.207+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:59:04.215+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.458 seconds
[2023-10-26T04:59:34.314+0000] {processor.py:156} INFO - Started process (PID=12659) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:59:34.315+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T04:59:34.316+0000] {logging_mixin.py:117} INFO - [2023-10-26T04:59:34.316+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:59:41.608+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T04:59:41.615+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.303 seconds
[2023-10-26T05:00:11.753+0000] {processor.py:156} INFO - Started process (PID=12798) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:11.754+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:00:11.756+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:00:11.756+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:18.516+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:18.524+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.775 seconds
[2023-10-26T05:00:48.899+0000] {processor.py:156} INFO - Started process (PID=12932) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:48.900+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:00:48.902+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:00:48.902+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:55.997+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:00:56.005+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.111 seconds
[2023-10-26T05:01:26.079+0000] {processor.py:156} INFO - Started process (PID=13066) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:01:26.080+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:01:26.081+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:01:26.081+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:01:33.299+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:01:33.308+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.224 seconds
[2023-10-26T05:02:03.399+0000] {processor.py:156} INFO - Started process (PID=13210) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:03.400+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:02:03.401+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:02:03.401+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:10.071+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:10.080+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.685 seconds
[2023-10-26T05:02:40.144+0000] {processor.py:156} INFO - Started process (PID=13345) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:40.146+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:02:40.147+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:02:40.147+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:47.912+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:02:47.920+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.779 seconds
[2023-10-26T05:03:18.751+0000] {processor.py:156} INFO - Started process (PID=13481) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:03:18.752+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:03:18.753+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:03:18.753+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:03:26.210+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:03:26.216+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.469 seconds
[2023-10-26T05:03:56.924+0000] {processor.py:156} INFO - Started process (PID=13624) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:03:56.925+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:03:56.926+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:03:56.926+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:04:03.967+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:04:03.977+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.048 seconds
[2023-10-26T05:04:34.362+0000] {processor.py:156} INFO - Started process (PID=13758) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:04:34.363+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:04:34.364+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:04:34.364+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:04:41.115+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:04:41.123+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.764 seconds
[2023-10-26T05:05:11.740+0000] {processor.py:156} INFO - Started process (PID=13892) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:11.741+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:05:11.742+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:05:11.742+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:18.697+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:18.704+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.966 seconds
[2023-10-26T05:05:49.525+0000] {processor.py:156} INFO - Started process (PID=14037) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:49.526+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:05:49.527+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:05:49.527+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:56.600+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:05:56.608+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.086 seconds
[2023-10-26T05:06:26.941+0000] {processor.py:156} INFO - Started process (PID=14173) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:06:26.943+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:06:26.944+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:06:26.944+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:06:34.038+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:06:34.053+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.104 seconds
[2023-10-26T05:07:04.114+0000] {processor.py:156} INFO - Started process (PID=14307) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:04.115+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:07:04.116+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:07:04.116+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:11.314+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:11.321+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.210 seconds
[2023-10-26T05:07:41.637+0000] {processor.py:156} INFO - Started process (PID=14441) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:41.638+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:07:41.640+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:07:41.640+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:49.544+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:07:49.553+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.919 seconds
[2023-10-26T05:08:19.750+0000] {processor.py:156} INFO - Started process (PID=14586) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:08:19.751+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:08:19.752+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:08:19.752+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:08:26.870+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:08:26.879+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.132 seconds
[2023-10-26T05:08:57.047+0000] {processor.py:156} INFO - Started process (PID=14720) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:08:57.049+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:08:57.050+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:08:57.050+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:09:05.369+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:09:05.377+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.324 seconds
[2023-10-26T05:09:35.479+0000] {processor.py:156} INFO - Started process (PID=14856) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:09:35.481+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:09:35.482+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:09:35.482+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:09:42.714+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:09:42.725+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.249 seconds
[2023-10-26T05:10:12.804+0000] {processor.py:156} INFO - Started process (PID=14999) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:12.806+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:10:12.813+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:10:12.812+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:19.457+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:19.465+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.665 seconds
[2023-10-26T05:10:49.894+0000] {processor.py:156} INFO - Started process (PID=15133) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:49.895+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:10:49.896+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:10:49.896+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:56.845+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:10:56.854+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.963 seconds
[2023-10-26T05:11:26.948+0000] {processor.py:156} INFO - Started process (PID=15269) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:11:26.949+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:11:26.950+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:11:26.950+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:11:35.062+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:11:35.070+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.112 seconds
[2023-10-26T05:12:05.579+0000] {processor.py:156} INFO - Started process (PID=15405) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:05.580+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:12:05.586+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:12:05.586+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:13.014+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:13.021+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.444 seconds
[2023-10-26T05:12:43.351+0000] {processor.py:156} INFO - Started process (PID=15552) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:43.352+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:12:43.354+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:12:43.354+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:50.235+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:12:50.244+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.896 seconds
[2023-10-26T05:13:21.077+0000] {processor.py:156} INFO - Started process (PID=15687) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:13:21.078+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:13:21.080+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:13:21.080+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:13:45.927+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:13:45.938+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 24.864 seconds
[2023-10-26T05:14:16.121+0000] {processor.py:156} INFO - Started process (PID=15826) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:14:16.123+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:14:16.127+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:14:16.127+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:14:30.487+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:14:30.495+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 14.378 seconds
[2023-10-26T05:15:00.772+0000] {processor.py:156} INFO - Started process (PID=15971) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:00.776+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:15:00.779+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:15:00.778+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:08.893+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:08.917+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.148 seconds
[2023-10-26T05:15:39.436+0000] {processor.py:156} INFO - Started process (PID=16107) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:39.437+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:15:39.438+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:15:39.438+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:44.442+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:15:44.449+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.016 seconds
[2023-10-26T05:16:14.637+0000] {processor.py:156} INFO - Started process (PID=16241) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:16:14.639+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:16:14.640+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:16:14.640+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:16:25.244+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:16:25.255+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.618 seconds
[2023-10-26T05:16:55.877+0000] {processor.py:156} INFO - Started process (PID=16376) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:16:55.879+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:16:55.881+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:16:55.880+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:17:01.854+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:17:01.861+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.986 seconds
[2023-10-26T05:17:31.961+0000] {processor.py:156} INFO - Started process (PID=16519) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:17:31.963+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:17:31.964+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:17:31.964+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:17:37.093+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:17:37.100+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.143 seconds
[2023-10-26T05:18:07.999+0000] {processor.py:156} INFO - Started process (PID=16655) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:08.001+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:18:08.002+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:18:08.002+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:13.803+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:13.810+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.813 seconds
[2023-10-26T05:18:44.135+0000] {processor.py:156} INFO - Started process (PID=16789) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:44.136+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:18:44.137+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:18:44.137+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:49.897+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:18:49.905+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.772 seconds
[2023-10-26T05:19:20.711+0000] {processor.py:156} INFO - Started process (PID=16924) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:19:20.712+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:19:20.714+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:19:20.714+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:19:26.195+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:19:26.201+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.494 seconds
[2023-10-26T05:19:57.041+0000] {processor.py:156} INFO - Started process (PID=17058) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:19:57.042+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:19:57.044+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:19:57.044+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:20:02.365+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:20:02.380+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.342 seconds
[2023-10-26T05:20:32.518+0000] {processor.py:156} INFO - Started process (PID=17193) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:20:32.519+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:20:32.520+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:20:32.520+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:20:38.994+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:20:39.019+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.502 seconds
[2023-10-26T05:21:09.261+0000] {processor.py:156} INFO - Started process (PID=17329) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:09.262+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:21:09.264+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:21:09.263+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:14.672+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:14.678+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.421 seconds
[2023-10-26T05:21:44.757+0000] {processor.py:156} INFO - Started process (PID=17464) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:44.758+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:21:44.760+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:21:44.759+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:49.603+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:21:49.610+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.883 seconds
[2023-10-26T05:22:20.034+0000] {processor.py:156} INFO - Started process (PID=17608) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:22:20.036+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:22:20.037+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:22:20.037+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:22:24.980+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:22:24.987+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.956 seconds
[2023-10-26T05:22:55.323+0000] {processor.py:156} INFO - Started process (PID=17742) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:22:55.325+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:22:55.326+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:22:55.326+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:23:00.602+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:23:00.610+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.289 seconds
[2023-10-26T05:23:31.084+0000] {processor.py:156} INFO - Started process (PID=17878) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:23:31.085+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:23:31.086+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:23:31.086+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:23:35.708+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:23:35.715+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.633 seconds
[2023-10-26T05:24:05.937+0000] {processor.py:156} INFO - Started process (PID=18014) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:05.939+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:24:05.940+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:24:05.939+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:11.021+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:11.028+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.094 seconds
[2023-10-26T05:24:41.471+0000] {processor.py:156} INFO - Started process (PID=18149) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:41.472+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:24:41.474+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:24:41.474+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:46.866+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:24:46.875+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.406 seconds
[2023-10-26T05:25:16.939+0000] {processor.py:156} INFO - Started process (PID=18284) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:16.940+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:25:16.940+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:25:16.940+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:21.922+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:21.928+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.992 seconds
[2023-10-26T05:25:52.564+0000] {processor.py:156} INFO - Started process (PID=18428) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:52.566+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:25:52.567+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:25:52.567+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:57.058+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:25:57.066+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.504 seconds
[2023-10-26T05:26:27.546+0000] {processor.py:156} INFO - Started process (PID=18562) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:26:27.548+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:26:27.550+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:26:27.550+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:26:32.019+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:26:32.025+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.482 seconds
[2023-10-26T05:27:02.537+0000] {processor.py:156} INFO - Started process (PID=18696) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:02.539+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:27:02.540+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:27:02.539+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:07.071+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:07.079+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.545 seconds
[2023-10-26T05:27:37.155+0000] {processor.py:156} INFO - Started process (PID=18833) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:37.156+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:27:37.158+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:27:37.158+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:41.705+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:27:41.711+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.559 seconds
[2023-10-26T05:28:12.208+0000] {processor.py:156} INFO - Started process (PID=18969) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:12.209+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:28:12.210+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:28:12.210+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:17.062+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:17.069+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.864 seconds
[2023-10-26T05:28:47.530+0000] {processor.py:156} INFO - Started process (PID=19106) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:47.532+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:28:47.533+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:28:47.533+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:52.545+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:28:52.553+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.025 seconds
[2023-10-26T05:29:23.225+0000] {processor.py:156} INFO - Started process (PID=19254) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:29:23.226+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:29:23.227+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:29:23.227+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:29:28.330+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:29:28.337+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.114 seconds
[2023-10-26T05:29:59.327+0000] {processor.py:156} INFO - Started process (PID=19390) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:29:59.328+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:29:59.330+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:29:59.329+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:30:04.664+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:30:04.672+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.347 seconds
[2023-10-26T05:30:34.981+0000] {processor.py:156} INFO - Started process (PID=19526) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:30:34.983+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:30:34.984+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:30:34.984+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:30:40.277+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:30:40.284+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.307 seconds
[2023-10-26T05:31:10.437+0000] {processor.py:156} INFO - Started process (PID=19662) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:10.438+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:31:10.441+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:31:10.440+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:15.462+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:15.470+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.036 seconds
[2023-10-26T05:31:46.068+0000] {processor.py:156} INFO - Started process (PID=19800) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:46.070+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:31:46.073+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:31:46.073+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:52.533+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:31:52.540+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.478 seconds
[2023-10-26T05:32:22.761+0000] {processor.py:156} INFO - Started process (PID=19938) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:32:22.762+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:32:22.763+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:32:22.763+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:32:29.647+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:32:29.660+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.901 seconds
[2023-10-26T05:33:00.518+0000] {processor.py:156} INFO - Started process (PID=20083) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:00.519+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:33:00.521+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:33:00.521+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:05.740+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:05.747+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.233 seconds
[2023-10-26T05:33:36.041+0000] {processor.py:156} INFO - Started process (PID=20219) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:36.042+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:33:36.043+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:33:36.043+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:41.289+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:33:41.298+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.259 seconds
[2023-10-26T05:34:11.409+0000] {processor.py:156} INFO - Started process (PID=20354) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:11.410+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:34:11.411+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:34:11.411+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:16.622+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:16.630+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.223 seconds
[2023-10-26T05:34:46.836+0000] {processor.py:156} INFO - Started process (PID=20491) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:46.837+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:34:46.840+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:34:46.840+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:53.628+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:34:53.636+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.803 seconds
[2023-10-26T05:35:24.488+0000] {processor.py:156} INFO - Started process (PID=20629) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:35:24.489+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:35:24.490+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:35:24.490+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:35:34.892+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:35:34.920+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.434 seconds
[2023-10-26T05:36:05.091+0000] {processor.py:156} INFO - Started process (PID=20774) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:05.092+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:36:05.094+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:36:05.093+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:12.962+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:12.981+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.892 seconds
[2023-10-26T05:36:43.118+0000] {processor.py:156} INFO - Started process (PID=20911) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:43.120+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:36:43.122+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:36:43.121+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:49.145+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:36:49.163+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.047 seconds
[2023-10-26T05:37:19.618+0000] {processor.py:156} INFO - Started process (PID=21047) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:37:19.619+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:37:19.621+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:37:19.621+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:37:25.110+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:37:25.117+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.502 seconds
[2023-10-26T05:37:56.043+0000] {processor.py:156} INFO - Started process (PID=21192) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:37:56.045+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:37:56.047+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:37:56.047+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:38:02.135+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:38:02.143+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.105 seconds
[2023-10-26T05:38:32.613+0000] {processor.py:156} INFO - Started process (PID=21330) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:38:32.614+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:38:32.615+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:38:32.615+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:38:38.406+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:38:38.415+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.805 seconds
[2023-10-26T05:39:08.608+0000] {processor.py:156} INFO - Started process (PID=21466) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:08.609+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:39:08.610+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:39:08.610+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:13.755+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:13.763+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.159 seconds
[2023-10-26T05:39:44.058+0000] {processor.py:156} INFO - Started process (PID=21601) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:44.060+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:39:44.061+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:39:44.061+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:49.658+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:39:49.667+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.613 seconds
[2023-10-26T05:40:19.898+0000] {processor.py:156} INFO - Started process (PID=21739) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:40:19.899+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:40:19.901+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:40:19.901+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:40:27.052+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:40:27.059+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.164 seconds
[2023-10-26T05:40:57.747+0000] {processor.py:156} INFO - Started process (PID=21877) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:40:57.748+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:40:57.749+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:40:57.749+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:41:02.861+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:41:02.868+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.124 seconds
[2023-10-26T05:41:33.837+0000] {processor.py:156} INFO - Started process (PID=22022) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:41:33.838+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:41:33.842+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:41:33.842+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:41:43.565+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:41:43.582+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 9.749 seconds
[2023-10-26T05:42:14.186+0000] {processor.py:156} INFO - Started process (PID=22156) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:14.188+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:42:14.189+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:42:14.189+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:20.728+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:20.740+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.557 seconds
[2023-10-26T05:42:51.315+0000] {processor.py:156} INFO - Started process (PID=22291) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:51.317+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:42:51.318+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:42:51.318+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:56.965+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:42:56.973+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.660 seconds
[2023-10-26T05:43:27.656+0000] {processor.py:156} INFO - Started process (PID=22437) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:43:27.658+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:43:27.659+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:43:27.659+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:43:32.697+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:43:32.704+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.051 seconds
[2023-10-26T05:44:03.007+0000] {processor.py:156} INFO - Started process (PID=22572) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:03.009+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:44:03.011+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:44:03.010+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:13.005+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:13.033+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.030 seconds
[2023-10-26T05:44:43.148+0000] {processor.py:156} INFO - Started process (PID=22708) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:43.150+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:44:43.151+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:44:43.151+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:49.709+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:44:49.716+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.571 seconds
[2023-10-26T05:45:19.842+0000] {processor.py:156} INFO - Started process (PID=22846) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:45:19.843+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:45:19.845+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:45:19.845+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:45:26.435+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:45:26.443+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.603 seconds
[2023-10-26T05:45:56.503+0000] {processor.py:156} INFO - Started process (PID=22992) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:45:56.505+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:45:56.506+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:45:56.506+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:46:01.986+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:46:01.993+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.493 seconds
[2023-10-26T05:46:32.329+0000] {processor.py:156} INFO - Started process (PID=23127) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:46:32.331+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:46:32.332+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:46:32.332+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:46:37.973+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:46:37.980+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.652 seconds
[2023-10-26T05:47:08.087+0000] {processor.py:156} INFO - Started process (PID=23265) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:08.088+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:47:08.089+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:47:08.088+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:14.474+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:14.484+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.401 seconds
[2023-10-26T05:47:44.765+0000] {processor.py:156} INFO - Started process (PID=23400) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:44.766+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:47:44.767+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:47:44.767+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:50.441+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:47:50.449+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.686 seconds
[2023-10-26T05:48:21.303+0000] {processor.py:156} INFO - Started process (PID=23535) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:48:21.304+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:48:21.306+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:48:21.305+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:48:31.471+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:48:31.489+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 10.189 seconds
[2023-10-26T05:49:01.712+0000] {processor.py:156} INFO - Started process (PID=23679) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:01.713+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:49:01.715+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:49:01.714+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:08.782+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:08.789+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 7.080 seconds
[2023-10-26T05:49:38.961+0000] {processor.py:156} INFO - Started process (PID=23818) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:38.962+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:49:38.964+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:49:38.963+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:44.454+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:49:44.465+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.507 seconds
[2023-10-26T05:50:14.995+0000] {processor.py:156} INFO - Started process (PID=23953) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:14.997+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:50:14.998+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:50:14.998+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:19.682+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:19.691+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.698 seconds
[2023-10-26T05:50:50.472+0000] {processor.py:156} INFO - Started process (PID=24089) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:50.474+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:50:50.475+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:50:50.475+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:55.129+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:50:55.137+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.667 seconds
[2023-10-26T05:51:25.918+0000] {processor.py:156} INFO - Started process (PID=24226) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:51:25.920+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:51:25.921+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:51:25.921+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:51:30.991+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:51:30.998+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.083 seconds
[2023-10-26T05:52:01.051+0000] {processor.py:156} INFO - Started process (PID=24360) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:01.052+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:52:01.053+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:52:01.053+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:06.002+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:06.010+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.961 seconds
[2023-10-26T05:52:36.883+0000] {processor.py:156} INFO - Started process (PID=24504) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:36.885+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:52:36.886+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:52:36.886+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:41.382+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:52:41.388+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.508 seconds
[2023-10-26T05:53:12.204+0000] {processor.py:156} INFO - Started process (PID=24640) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:12.206+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:53:12.207+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:53:12.207+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:16.741+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:16.749+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.550 seconds
[2023-10-26T05:53:47.067+0000] {processor.py:156} INFO - Started process (PID=24777) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:47.069+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:53:47.070+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:53:47.069+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:52.002+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:53:52.009+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.945 seconds
[2023-10-26T05:54:22.168+0000] {processor.py:156} INFO - Started process (PID=24913) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:54:22.170+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:54:22.171+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:54:22.171+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:54:27.490+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:54:27.496+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.331 seconds
[2023-10-26T05:54:58.033+0000] {processor.py:156} INFO - Started process (PID=25046) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:54:58.034+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:54:58.035+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:54:58.035+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:55:03.611+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:55:03.618+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.587 seconds
[2023-10-26T05:55:33.896+0000] {processor.py:156} INFO - Started process (PID=25180) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:55:33.898+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:55:33.899+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:55:33.899+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:55:38.999+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:55:39.006+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.113 seconds
[2023-10-26T05:56:09.267+0000] {processor.py:156} INFO - Started process (PID=25316) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:09.269+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:56:09.270+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:56:09.270+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:14.132+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:14.140+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.875 seconds
[2023-10-26T05:56:44.594+0000] {processor.py:156} INFO - Started process (PID=25459) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:44.595+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:56:44.596+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:56:44.596+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:49.432+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:56:49.439+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.847 seconds
[2023-10-26T05:57:20.043+0000] {processor.py:156} INFO - Started process (PID=25597) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:20.045+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:57:20.047+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:57:20.046+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:24.593+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:24.599+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.559 seconds
[2023-10-26T05:57:54.847+0000] {processor.py:156} INFO - Started process (PID=25732) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:54.848+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:57:54.849+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:57:54.849+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:59.497+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:57:59.503+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.659 seconds
[2023-10-26T05:58:29.556+0000] {processor.py:156} INFO - Started process (PID=25867) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:58:29.558+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:58:29.559+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:58:29.559+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:58:34.099+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:58:34.106+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.553 seconds
[2023-10-26T05:59:04.327+0000] {processor.py:156} INFO - Started process (PID=26004) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:04.328+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:59:04.329+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:59:04.329+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:09.101+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:09.108+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.784 seconds
[2023-10-26T05:59:39.165+0000] {processor.py:156} INFO - Started process (PID=26140) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:39.167+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T05:59:39.168+0000] {logging_mixin.py:117} INFO - [2023-10-26T05:59:39.167+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:44.015+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T05:59:44.023+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.862 seconds
[2023-10-26T06:00:14.678+0000] {processor.py:156} INFO - Started process (PID=26274) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:14.679+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:00:14.680+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:00:14.680+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:19.378+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:19.385+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.709 seconds
[2023-10-26T06:00:49.462+0000] {processor.py:156} INFO - Started process (PID=26419) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:49.464+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:00:49.465+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:00:49.465+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:53.990+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:00:53.996+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.536 seconds
[2023-10-26T06:01:24.225+0000] {processor.py:156} INFO - Started process (PID=26554) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:01:24.226+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:01:24.227+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:01:24.227+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:01:29.192+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:01:29.200+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.977 seconds
[2023-10-26T06:01:59.572+0000] {processor.py:156} INFO - Started process (PID=26693) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:01:59.574+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:01:59.576+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:01:59.576+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:02:05.498+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:02:05.506+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.936 seconds
[2023-10-26T06:02:36.114+0000] {processor.py:156} INFO - Started process (PID=26828) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:02:36.116+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:02:36.118+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:02:36.118+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:02:41.070+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:02:41.083+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.973 seconds
[2023-10-26T06:03:11.932+0000] {processor.py:156} INFO - Started process (PID=26963) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:03:11.934+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:03:11.936+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:03:11.936+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:03:25.784+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:03:25.886+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 13.952 seconds
[2023-10-26T06:03:56.285+0000] {processor.py:156} INFO - Started process (PID=27110) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:03:56.299+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:03:56.302+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:03:56.301+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:04:04.465+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:04:04.472+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 8.244 seconds
[2023-10-26T06:04:35.244+0000] {processor.py:156} INFO - Started process (PID=27248) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:04:35.246+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:04:35.247+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:04:35.247+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:04:40.397+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:04:40.404+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.163 seconds
[2023-10-26T06:05:10.771+0000] {processor.py:156} INFO - Started process (PID=27383) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:10.773+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:05:10.774+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:05:10.774+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:15.958+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:15.966+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.196 seconds
[2023-10-26T06:05:46.116+0000] {processor.py:156} INFO - Started process (PID=27519) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:46.117+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:05:46.118+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:05:46.118+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:51.281+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:05:51.287+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.174 seconds
[2023-10-26T06:06:21.459+0000] {processor.py:156} INFO - Started process (PID=27654) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:06:21.460+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:06:21.461+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:06:21.461+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:06:28.177+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:06:28.218+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 6.762 seconds
[2023-10-26T06:06:58.784+0000] {processor.py:156} INFO - Started process (PID=27789) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:06:58.785+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:06:58.786+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:06:58.786+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:07:04.524+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:07:04.531+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.750 seconds
[2023-10-26T06:07:35.160+0000] {processor.py:156} INFO - Started process (PID=27926) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:07:35.161+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:07:35.162+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:07:35.162+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:07:40.331+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:07:40.340+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 5.183 seconds
[2023-10-26T06:08:11.048+0000] {processor.py:156} INFO - Started process (PID=28072) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:08:11.049+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:08:11.051+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:08:11.051+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:08:16.012+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:08:16.019+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 4.975 seconds
[2023-10-26T06:54:29.817+0000] {processor.py:156} INFO - Started process (PID=272) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:54:29.819+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:54:29.820+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:54:29.820+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:55:00.954+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:55:00.695+0000] {timeout.py:68} ERROR - Process timed out, PID: 272
[2023-10-26T06:55:02.128+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:55:01.495+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 272
[2023-10-26T06:55:02.133+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:55:04.328+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 34.374 seconds
[2023-10-26T06:56:17.981+0000] {processor.py:156} INFO - Started process (PID=332) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:56:17.982+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:56:17.984+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:56:17.984+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:56:47.996+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:56:47.985+0000] {timeout.py:68} ERROR - Process timed out, PID: 332
[2023-10-26T06:56:48.067+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:56:48.027+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 332
[2023-10-26T06:56:48.087+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:56:58.387+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T06:57:32.367+0000] {processor.py:156} INFO - Started process (PID=383) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:57:32.381+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:57:32.387+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:57:32.386+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:58:03.253+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:58:02.793+0000] {timeout.py:68} ERROR - Process timed out, PID: 383
[2023-10-26T06:58:08.981+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:58:04.574+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 383
[2023-10-26T06:58:11.506+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:58:21.665+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T06:59:16.295+0000] {processor.py:156} INFO - Started process (PID=441) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:59:16.296+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T06:59:16.298+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:59:16.298+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:59:46.508+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:59:46.400+0000] {timeout.py:68} ERROR - Process timed out, PID: 441
[2023-10-26T06:59:46.912+0000] {logging_mixin.py:117} INFO - [2023-10-26T06:59:46.664+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp6wncf3hd/tmpo3oyooti'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 441
[2023-10-26T06:59:46.984+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T06:59:59.211+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T07:00:30.675+0000] {processor.py:156} INFO - Started process (PID=495) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:00:30.680+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:00:30.684+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:00:30.682+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:01:00.784+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:01:00.777+0000] {timeout.py:68} ERROR - Process timed out, PID: 495
[2023-10-26T07:01:00.815+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:01:00.797+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 495
[2023-10-26T07:01:00.827+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:01:11.088+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T07:03:34.782+0000] {processor.py:156} INFO - Started process (PID=545) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:03:34.790+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:03:34.795+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:03:34.793+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:04:06.467+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:04:05.029+0000] {timeout.py:68} ERROR - Process timed out, PID: 545
[2023-10-26T07:04:12.106+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:04:12.059+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp4c86alz9/tmpgotg7rxw'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 545
[2023-10-26T07:04:12.114+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:04:25.690+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T07:06:59.603+0000] {processor.py:156} INFO - Started process (PID=591) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:06:59.605+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:06:59.616+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:06:59.615+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:07:29.951+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:07:29.707+0000] {timeout.py:68} ERROR - Process timed out, PID: 591
[2023-10-26T07:07:33.155+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:07:30.602+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 105, in launch_gateway
    time.sleep(0.1)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 591
[2023-10-26T07:07:35.165+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:07:46.058+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T07:09:58.981+0000] {processor.py:156} INFO - Started process (PID=41) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:09:58.984+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:09:58.985+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:09:58.985+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:10:14.521+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.501+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[2023-10-26T07:10:14.524+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.524+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.551+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.539+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T07:10:14.554+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.554+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.566+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.566+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.567+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.567+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.596+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.595+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.605+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.604+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.606+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.606+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.607+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.607+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.611+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.610+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.614+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.613+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.621+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.618+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.627+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.627+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.628+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.628+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.637+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.636+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.638+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.638+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.641+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.641+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.642+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.642+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:14.653+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:14.652+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:10:17.233+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:10:17.232+0000] {process_utils.py:256} INFO - Waiting up to 5 seconds for processes to exit...
[2023-10-26T07:13:45.202+0000] {processor.py:156} INFO - Started process (PID=31) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:13:45.206+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:13:45.208+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:13:45.207+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:14:04.579+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:14:04.614+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 19.414 seconds
[2023-10-26T07:14:35.021+0000] {processor.py:156} INFO - Started process (PID=165) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:14:35.024+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:14:35.027+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:14:35.026+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:15:05.191+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.117+0000] {timeout.py:68} ERROR - Process timed out, PID: 165
[2023-10-26T07:15:05.329+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.228+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 165
[2023-10-26T07:15:05.390+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.355+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:15:05.506+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.425+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 165

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T07:15:05.563+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.559+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:15:05.610+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:05.564+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T07:15:05.680+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:15:16.239+0000] {processor.py:181} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 177, in _run_file_processor
    _handle_dag_file_processing()
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 161, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 771, in process_file
    self.update_import_errors(session, dagbag)
  File "/usr/local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 558, in update_import_errors
    existing_import_error_files = [x.filename for x in session.query(errors.ImportError.filename).all()]
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3375, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2209, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-10-26T07:15:46.607+0000] {processor.py:156} INFO - Started process (PID=260) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:15:46.608+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:15:46.611+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:15:46.611+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:16:16.741+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:16.664+0000] {timeout.py:68} ERROR - Process timed out, PID: 260
[2023-10-26T07:16:17.046+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:16.844+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 260
[2023-10-26T07:16:17.063+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:17.062+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:16:17.136+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:17.067+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 260

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T07:16:17.198+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:17.169+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:16:17.309+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:17.237+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T07:16:17.404+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:16:53.281+0000] {processor.py:156} INFO - Started process (PID=362) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:16:53.282+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:16:53.284+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:16:53.284+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:17:23.601+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:23.541+0000] {timeout.py:68} ERROR - Process timed out, PID: 362
[2023-10-26T07:17:24.006+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:23.718+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 362
[2023-10-26T07:17:24.698+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:24.280+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:17:25.643+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:24.963+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 362

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T07:17:26.956+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:26.244+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:17:34.081+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:17:28.636+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T07:17:41.205+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:19:22.115+0000] {processor.py:156} INFO - Started process (PID=459) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:19:22.151+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:19:22.177+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:19:22.177+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:19:53.795+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:19:53.123+0000] {timeout.py:68} ERROR - Process timed out, PID: 459
[2023-10-26T07:19:55.598+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:19:54.434+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmphc1bcwby/tmp93n0wowz'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 459
[2023-10-26T07:19:56.434+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:21:47.767+0000] {processor.py:156} INFO - Started process (PID=503) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:21:47.780+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:21:47.781+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:21:47.781+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:22:23.667+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:22:23.592+0000] {timeout.py:68} ERROR - Process timed out, PID: 503
[2023-10-26T07:22:24.244+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:22:23.885+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/subprocess.py", line 991, in poll
    return self._internal_poll()
  File "/usr/local/lib/python3.7/subprocess.py", line 1599, in _internal_poll
    if not self._waitpid_lock.acquire(False):
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 503
[2023-10-26T07:22:24.276+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:22:25.752+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/script/spark_csv.py took 37.947 seconds
[2023-10-26T07:23:27.681+0000] {processor.py:156} INFO - Started process (PID=576) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:23:27.686+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:23:27.688+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:23:27.688+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:24:35.606+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:24:35.463+0000] {timeout.py:68} ERROR - Process timed out, PID: 576
[2023-10-26T07:24:35.695+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:24:35.642+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpnq37f6l8/tmpwnwvc4g5'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 144, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 339, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    while not proc.poll() and not os.path.isfile(conn_info_file):
  File "/usr/local/lib/python3.7/genericpath.py", line 30, in isfile
    st = os.stat(path)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 576
[2023-10-26T07:24:35.724+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:25:52.729+0000] {processor.py:156} INFO - Started process (PID=32) to work on /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:25:52.731+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/script/spark_csv.py for tasks to queue
[2023-10-26T07:25:52.732+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:25:52.732+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/script/spark_csv.py
[2023-10-26T07:26:27.788+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:23.004+0000] {timeout.py:68} ERROR - Process timed out, PID: 32
[2023-10-26T07:26:32.269+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:29.693+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 32
[2023-10-26T07:26:32.349+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:32.301+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:26:32.558+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:32.455+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/script/spark_csv.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.4.0/best-practices.html#reducing-dag-complexity, PID: 32

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/usr/local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-10-26T07:26:32.573+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:32.572+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-10-26T07:26:32.600+0000] {logging_mixin.py:117} INFO - [2023-10-26T07:26:32.574+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/script/spark_csv.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/script/spark_csv.py", line 9, in <module>
    "spark.jars", "/opt/spark/assembly/target/scala-2.12/jars/postgresql-42.2.5.jar"
  File "/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 147, in __init__
    conf, jsc, profiler_cls)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/usr/local/lib/python3.7/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/usr/local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2023-10-26T07:26:32.610+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/script/spark_csv.py
